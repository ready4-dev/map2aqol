---
title: "Economic analysis"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Economic analysis}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
params:
  output_type_1L_chr: HTML
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r message=FALSE}
library(youthu)
set.seed(1234)
```
# Introduction

## Motivation
The main motivation behind the youthu package is to extend the types of economic analysis that can be undertaken with both single group (e.g. pilot study, health service records) and matched groups (e.g. trial) datasets that do not include measures of health utility.

## Example datasets
To illustrate the input data requirements and the practical application of youthu functions, we adapt a   [replication dataset from the youthu's sister package TTU](https://ready4-dev.github.io/TTU/articles/Replication_DS.html) to create synthetic (fake) single group and matched group datasets. To do so, we first make a list object `ds_smry_ls` that summarises the desired features of these datasets, such as:

 - the names of the predictors for utility to be included in the dataset;
 - the name of variables for unique unit identifier, data collection round, data collection date, costs and health utility measure;
 - (for matched dataset only) the name of the variable for comparison group and the allowable values for that variable;
 - the allowed values of the data collection round variable, the dates during which baseline data measures are collected (randomly sampled from a sequence of 180 consecutive days from the last year) and distribution parameters for the duration between baseline and follow-up timepoints (sampled from a truncated normal distribution, bounded between 80 and 110 days);
 - **population** (not sample) parameters to generate gamma distributed costs for periods prior to study entry(mean \$300) and between baseline and follow-up measurements (mean \$1500) for the whole single group dataset or the control arm of a matched dataset;
 
```{r}
ds_smry_ls <- list(bl_start_date_dtm = Sys.Date() - lubridate::days(300),
                   bl_end_date_dtm = Sys.Date() - lubridate::days(120),
                   cmprsn_var_nm_1L_chr = "study_arm_chr",
                   cmprsn_groups_chr = c("Intervention","Control"),
                   costs_mean_dbl = c(300,1500),
                   costs_sd_dbl = c(100,120),
                   costs_var_nm_1L_chr = "costs_dbl",
                   date_var_nm_1L_chr = "date_psx",
                   duration_args_ls = list(a = 80, b = 110, mean = 90, sd = 7),
                   duration_fn = truncnorm::rtruncnorm,
                   id_var_nm_1L_chr = "fkClientID",
                   predr_var_nms = c("PHQ9", "SOFAS"),
                   round_var_nm_1L_chr = "round",
                   round_lvls_chr = c("Baseline","Follow-up"), 
                   utl_var_nm_1L_chr = "AQoL6D_HU")

```
We pass both the `ds_smry_ls` summary list and the `replication_popl_tb` replication dataset to the `make_sngl_grp_ds`{.R} function to create an example single group dataset.
```{r}
sngl_grp_ds_tb <- make_sngl_grp_ds(TTU::replication_popl_tb,ds_smry_ls = ds_smry_ls)
```

We can split a subset of our single group dataset into two propensity score matched groups - one each for intervention and control - using the `make_matched_ds`{.R} function. We also use this function to build in our assumptions about group differences in changes in PHQ9, SOFAS and costs measured at follow-up. The below example assumes **population** (not sample) mean change differences between Intervention and Control arms of -2 for PHQ9, -2 for SOFAS and +$300 for costs.

```{r}
matched_ds_tb <- make_matched_ds(sngl_grp_ds, 
                                 cmprsn_smry_tb = tibble::tibble(var_nms_chr = c(ds_smry_ls$predr_var_nms, ds_smry_ls$costs_var_nm_1L_chr),
                                 fns_ls = list(rnorm,rnorm,rnorm),
                                 abs_mean_diff_dbl = c(3,2,300),
                                 diff_sd_dbl = c(2,2,200),
                                 multiplier_dbl = c(-1,-1,1),
                                 min_dbl = c(0,0,0),
                                 max_dbl = c(27,100,Inf),
                                 integer_lgl = c(T,T,F)), 
                                 ds_smry_ls = ds_smry_ls)
```

# Economic analysis of matched group datasets

## Data requirements
The synthetic matched dataset we generated includes `r matched_ds_tb$match_idx_int %>% unique() %>% length()` matched comparisons, with each comparison containing baseline and follow-up records for one intervention arm participant and one control arm participant. The first few records are as follows.

```{r}
matched_ds_tb %>% head()
```
This dataset contains features that make it possible to use in conjunction with youthu's economic analysis functions. Specifically these requirements are that the dataset must:

- [include one or more of the predictors used in the youthu models](Prediction_With_Mdls.html) (in this case PHQ9 and SOFAS);
 - include variables for unique study participant identifier, data collection round, data collection date, interval between baseline and follow-up, study arm assignment and record matching; and
 - be in long format where each row represents ***either*** a baseline or follow-up measurement for a unique study participant.
 
The synthetic matched dataset also contains a cost variable, which is a requirement for most, though not all, of the economic analyses that can be undertaken with youthu. 

## Limitations of datasets without measures of health utility
A notable omission from the fake study dataset is any measure of utility. This omission means that, in the absence of using mapping algorithms such as those included with youthu, the most feasible types of economic evaluation to apply to this dataset would likely be cost-consequence analysis (where a synopsis of the differences in a range of measures are presented alongside cost differences for a decision maker to interpret subjectively) and cost-effectiveness analysis (where a statistic - the incremental cost-effectiveness ratio or ICER - is calculated by dividing differences in costs by differences in a single outcome measure).

These types of economic analyses can be relatively simple to interpret if either the intervention or control arm is simultaneously cheaper and more effective across all included outcome measures. However, these conditions don't hold in our sample data.

```{r}
summary((matched_ds_tb %>% dplyr::filter(study_arm_chr == "Control" & round == "Baseline"))[5:6])
```
```{r}
summary((matched_ds_tb %>% dplyr::filter(study_arm_chr == "Control" & round == "Follow-up"))[5:7])
```

```{r}
summary((matched_ds_tb %>% dplyr::filter(study_arm_chr == "Intervention" & round == "Baseline"))[5:6])
```

```{r}
summary((matched_ds_tb %>% dplyr::filter(study_arm_chr == "Intervention" & round == "Follow-up"))[5:7])
```

The results summarised above create some significant barriers to meaningfully interpreting economic evaluations that are based on cost-consequence or cost-effectiveness analysis:

- A cost-effectiveness analysis in which change in PHQ-9 was the benefit measure would be difficult to interpret as the Intervention arm is both more effective and more costly, which begs the question is it worth paying the extra dollars for the improvement as measured on the PHQ-9 scale? It is likely that, unlike the Quality Adjusted Life Year (QALY) outcome measure, there is no commonly used value for money benchmark for improvements measured in PHQ-9. Similarly, if the potential funding for the intervention is from a budget that is allocated to non-depressive illnesses (e.g. physical health), a PHQ-9 based cost-effectiveness analysis is not readily comparable with economic evaluations of other interventions potentially competing for these scarce funds.

- A cost consequence analyses that summarised the differences in costs with the differences in changes in PHQ-9 and SOFAS score would be difficult to interpret because while the intervention is more effective than control for improvements measured on PHQ-9 (where lower scores are better), the control group is superior if benefits are based on functioning improvements as measured by SOFAS scores (where higher scores are better). The lack of any formal weighting for how to trade off clinical symptoms and functioning means that interpretation of this analysis will be highly subjective and likely to change across potential decision makers.

These types of short-comings can be significantly addressed by undertaking cost-utility analyses (CUAs) as:

- they use a measure of benefit - the QALY - that captures multiple domains of health, weighted by time and population preferences in a single index measure that can be applied across health conditions;
- there are published benchmark willingness to pay values for use by decision makers in many countries to make ICER statistics readily interpretable.

The rest of this article demonstrates how youthu functions can be used to undertake CUA based analyses on the type of data we have just profiled.

## Using youthu in a cost-utility analysis workflow

Our first step is to identify which youthu models we will use to predict adolescent AQoL-6D  and apply these models to our data. This step was explained in more detail in [another vignette article](Prediction_With_Mdls.html), so will be dealt with briefly here.

First we retrieve the model we wish to use.

```{r}
candidate_mdls_tb <- get_mdls_using_predrs(predictors_lup$short_name_chr[c(5,7)])
model_mdl <- get_mdl_from_dv(candidate_mdls_tb$mdl_nms_chr[4])
```

We then use that model to predict health utility from the measures in our dataset.
```{r}
econ_cmprsn_ds_tb <- add_aqol6d_predn_to_ds(data_tb = matched_ds_tb,
                                   model_mdl = model_mdl,
                                   tfmn_1L_chr = get_tfmn_from_lup(candidate_mdls_tb$mdl_nms_chr[4]),
                                   utl_var_nm_1L_chr = ds_smry_ls$utl_var_nm_1L_chr,
                                   id_var_nm_1L_chr = ds_smry_ls$id_var_nm_1L_chr,
                                   round_var_nm_1L_chr = ds_smry_ls$round_var_nm_1L_chr,
                                   round_bl_val_1L_chr = ds_smry_ls$round_lvls_chr[1]) %>%
  dplyr::select(fkClientID, round, study_arm_chr, date_psx, duration_prd, dplyr::everything())
```
```{r}
econ_cmprsn_ds_tb %>% head() %>%
    ready4show::print_table(output_type_1L_chr = "HTML",
                          caption_1L_chr = "Updated dataset with predicted utility", 
                          use_lbls_as_col_nms_1L_lgl = T)
```
Next we combine the health utility data with the interval between measurement data to calculate QALYs and add them to the dataset.

```{r}
econ_cmprsn_ds_tb  <- econ_cmprsn_ds_tb %>% add_qalys_to_ds(ds_smry_ls = ds_smry_ls)
```

```{r}
econ_cmprsn_ds_tb %>% head() %>%
    ready4show::print_table(output_type_1L_chr = "HTML",
                          caption_1L_chr = "Updated dataset with QALYs", 
                          use_lbls_as_col_nms_1L_lgl = T)
```
Now we can run the main economic analysis. This is implemented by the `make_he_smry`{.R} function, which first bootstraps the dataset (implemented by the `boot` function from the `boot` package) before passing the mean values for costs and qalys from each bootstrap sample to with `bcea` function of the `BCEA` package to calculate a range of health economic statistics. For this example we pass a value of 50,000 for the willingness to pay parameter, as this is the dollar amount commonly used in Australia as a benchmark for the value of a QALY.

Note, for this illustrative example we only request 100 bootstrap iterations - in practice this number would be much higher.

```{r}
he_smry_ls <- econ_cmprsn_ds_tb %>% make_he_smry(change_vars_chr = c(ds_smry_ls$predr_var_nms,
                                                                     ds_smry_ls$utl_var_nm_1L_chr),
                                                 wtp_dbl = 50000,
                                                 bootstrap_iters_1L_int = 100L,
                                                 change_types_chr = c("dbl","dbl","dbl"),
                                                 benefits_pfx_1L_chr = "qalys_dbl",
                                                 benefits_var_nm_1L_chr = "qalys",
                                                 costs_pfx_1L_chr = ds_smry_ls$costs_var_nm_1L_chr,
                                                 costs_var_nm_1L_chr = "costs",
                                                 change_sfx_1L_chr = "change",
                                                 cmprsn_groups_chr = ds_smry_ls$cmprsn_groups_chr,
                                                 cmprsn_var_nm_1L_chr = ds_smry_ls$cmprsn_var_nm_1L_chr,
                                                 round_fup_1L_chr = ds_smry_ls$round_lvls_chr[2])
```

As part of the output of the `make_he_smry`{.R} function is a BCEA object, we can use the BCEA package to produce a number of graphical summaries of economic results. One of the most important is the production of a cost-effectiveness plane. This plot highlights that, with an ICER of \$`r he_smry_ls$ce_res_ls$ICER %>% format(big.mark =",")`, most of the bootstrapped iteration incremental cost and QALY pairs fall within the zone of cost-effectiveness (green). In fact at the cost-effectiveness threshold we supplied, our results suggest there is a `r he_smry_ls$ce_res_ls$ceac[he_smry_ls$ce_res_ls$k==50000] * 100`% probability that the intervention is cost-effective.

```{r fig.width=6}
BCEA::ceplane.plot(he_smry_ls$ce_res_ls, wtp =50000,    
                   area_color = "green",
                    graph = "ggplot2",
          theme = ggplot2::theme_light())
```
